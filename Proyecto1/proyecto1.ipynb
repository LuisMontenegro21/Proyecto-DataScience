{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0894d108",
   "metadata": {},
   "source": [
    "# Primera entrega\n",
    "Luis Montenegro - 21699<br>\n",
    "Javier Prado - 21486<br>\n",
    "Bryan España<br>\n",
    "Ángel Herrarte<br>\n",
    "\n",
    "\n",
    "## Limpieza de datos\n",
    "En esta entrega se hará una recolección y limpieza de datos solamente. No habrá modelado ni análisis. \n",
    "<br>Solamente velar por la integridad, coherencia y cohesión del conjunto de datos.facilidad de manejo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3fcc9",
   "metadata": {},
   "source": [
    "### Conversión de .xls a .csv\n",
    "\n",
    "Debido a que los archivos crudos descargados desde la página del Mineduc vienen en formato .xls formateado como .html tenemos que hacer cambio de eso.<br>\n",
    "Esto por múltiples razones:\n",
    "- Mejorar la estructura de los datos.\n",
    "- Preservar solamente la información requerida (los .xls almaceban más páginas e información irrelevante)\n",
    "- Mayor falicidad de usar y obtener los datos si están en formato delimitado por comas.\n",
    "- Tener datos más ligeros ya que no acarreamos con mucha información innecesaria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456d91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_html_to_csv(input_path: str, output_path: str=None, tables_to_convert: list[int] = [9]) -> None:\n",
    "    '''\n",
    "    Turns .html files into .csv files\n",
    "\n",
    "    Params:\n",
    "        input_path: where the .html files are stored\n",
    "        output_path: where the .csv will be stored\n",
    "    Returns:\n",
    "        out: None\n",
    "    '''\n",
    "    if output_path is None:\n",
    "        output_path = input_path \n",
    "    else:\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for filename in tqdm(os.listdir(input_path), desc='Converting Files'):\n",
    "        if filename.endswith('.xls'):\n",
    "            html_path:str = os.path.join(input_path, filename)\n",
    "            base_name:str = os.path.splitext(filename)[0]\n",
    "            # try to read the excel and copy it into a .csv file\n",
    "            try: \n",
    "                tables:list[pd.DataFrame] = pd.read_html(html_path)\n",
    "                # if no tables, skip\n",
    "                if not tables:\n",
    "                    print(f\"No tables found in '{filename}'\")\n",
    "                    continue\n",
    "\n",
    "                # convert each of the tables selected to .csv\n",
    "                for i, df in enumerate(tables):\n",
    "                    if i in tables_to_convert:\n",
    "                        csv_filename = f\"{base_name}_table{i}.csv\"\n",
    "                        csv_path = os.path.join(output_path, csv_filename)\n",
    "                        df.to_csv(csv_path, index=False)\n",
    "                        print(f\"Converted '{filename}' to '{csv_filename}'\") # print all of the transformations of the .xls to its respective .csv files\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file '{filename}' : {e}\")\n",
    "\n",
    "def remove_files(path: str, extension: str) -> None:\n",
    "    '''\n",
    "    Removes all files that have a certain extension\n",
    "    Input:\n",
    "        path: folder path where .xls to be removed are stored\n",
    "    '''\n",
    "    file_list: list[str] = os.listdir(path)\n",
    "    if not file_list:\n",
    "        print(f\"No files removed since there was none found: '{path}'\")\n",
    "        return\n",
    "\n",
    "    for filename in file_list:\n",
    "    \n",
    "        if filename.endswith(extension):\n",
    "            try:\n",
    "                xls_path = os.path.join(path, filename)\n",
    "                os.remove(xls_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing file '{filename}' : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f249f5f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: '../Dataset_raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# start by turning .xls files to .csv files\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtransform_html_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../Dataset_raw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../Dataset_cleaned\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtables_to_convert\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtransform_html_to_csv\u001b[39m\u001b[34m(input_path, output_path, tables_to_convert)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     14\u001b[39m     os.makedirs(output_path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m, desc=\u001b[33m'\u001b[39m\u001b[33mConverting Files\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filename.endswith(\u001b[33m'\u001b[39m\u001b[33m.xls\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     18\u001b[39m         html_path:\u001b[38;5;28mstr\u001b[39m = os.path.join(input_path, filename)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] El sistema no puede encontrar la ruta especificada: '../Dataset_raw'"
     ]
    }
   ],
   "source": [
    "# start by turning .xls files to .csv files\n",
    "transform_html_to_csv(input_path=\"../Dataset_raw\", output_path=\"../Dataset_cleaned\", tables_to_convert=[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81a4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files removed since there was none found: '../Dataset_raw'\n"
     ]
    }
   ],
   "source": [
    "# remove .xls files if necessary\n",
    "remove_files(path=\"../Dataset_raw\", extension='.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e543e",
   "metadata": {},
   "source": [
    "### Plan para limpieza de datos\n",
    "Posteriormente a la transformación de formato y filtración a solo datos crudos de nuestro interés, procederemos a limpiar los datos en sí. <br>\n",
    "1. Verificaremos si existe datos NA o Null en los archivos. Llenaremos los datos faltantes con datos artificiales ya que no podemos eliminar ningún registro <br>\n",
    "debido a que si eliminamos alguno, sería una sede faltante. Cosa que afectaría de gran manera el conjunto de datos.\n",
    "2. Homogenizaremos la información. Es decir, que todos los archivos tengan el mismo formato i.e. todos los nombres estén escritos igual, los apellidos que tienen tildes se escriban igual en cada archivo,\n",
    "que las palabras vengan o solo en mayúsculas, solo en minúsculas, etc.\n",
    "3. Identificaremos las columnas que más trabajo de reajuste necesiten.\n",
    "- Nombres (Supervisor, Director, Establecimiento, Sector): debido a que puede que exista apellidos iguales pero escritos distinto y eso genere problemas a la hora de verlos. Digamos, puede que Hernández aparezca con tilde en unos registros y en otros no. También es bueno verificar que estén escritos todos o en mayúsculas o en minúsculas (o todos iguales), ya que digamos, si tenemos Santa rosa en un registro y Santa Rosa en otro, a la hora de hacer un encoding estos resultarán con dos valores distintos. \n",
    "- Dirección: Asegurarnos que las direcciones lleven una estructura similar.\n",
    "- Códigos: Verificar que los códigos de los registros sean únicos y evitar tener repetidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6208bf",
   "metadata": {},
   "source": [
    "El conjunto de datos corresponde a los establecimientos educativos de Guatemala que llegan hasta el nivel diversificado. Está organizado en 85 archivos CSV, uno por cada departamento y municipio del país.\n",
    "\n",
    "Cada archivo contiene información detallada de cada establecimiento, como el nombre del centro, su ubicación, datos de contacto, modalidad de enseñanza y otros datos administrativos.\n",
    "\n",
    "\n",
    "Los archivos csv estan clasificados por departamentos de Guatemala. Las variables que contiene esta dataset son las siguientes sumando un total de 17 variables a analizar.\n",
    "\n",
    "- CODIGO: código único del establecimiento\n",
    "\n",
    "- DISTRITO: distrito educativo\n",
    "\n",
    "- DEPARTAMENTO: nombre del departamento\n",
    "\n",
    "- MUNICIPIO: municipio donde se ubica\n",
    "\n",
    "- ESTABLECIMIENTO: nombre del centro educativo\n",
    "\n",
    "- DIRECCION: dirección física\n",
    "\n",
    "- TELEFONO: número de contacto\n",
    "\n",
    "- SUPERVISOR: nombre del supervisor\n",
    "\n",
    "- DIRECTOR: nombre del director\n",
    "\n",
    "- NIVEL: nivel educativo (ej. Básico, Diversificado)\n",
    "\n",
    "- SECTOR: sector oficial o privado\n",
    "\n",
    "- AREA: área urbana o rural\n",
    "\n",
    "- STATUS: estado del centro (ej. Abierta)\n",
    "\n",
    "- MODALIDAD: modalidad lingüística (ej. Monolingüe, Bilingüe)\n",
    "\n",
    "- JORNADA: jornada de estudio (ej. Matutina, Vespertina)\n",
    "\n",
    "- PLAN: plan educativo (ej. Diario, Fin de semana)\n",
    "\n",
    "- DEPARTAMENTAL: nombre del departamento de adscripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5db5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto-env (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
